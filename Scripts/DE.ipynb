{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import listdir\n",
    "from fnmatch import fnmatch\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from astropy import wcs\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import sys\n",
    "sys.path.insert(1, 'TPA/pavlidis/build/lib.win-amd64-3.9')\n",
    "from pavlidis import pavlidis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def insideCoordinate(img, x, y):\n",
    "    if img[y,x-1] == 255 and img[y,x+1] == 255 and img[y-1,x] == 255 and img[y+1,x] == 255:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def getEdgeCoordinates(array_2d, cx, cy):\n",
    "    y1, x1, y2, x2 = array_2d[:,0].min(), array_2d[:,1].min(), array_2d[:,0].max()+1, array_2d[:,1].max()+1\n",
    "    vertical_diff = 0\n",
    "    if y2 - y1 < 81:\n",
    "        vertical_diff = 81 - (y2 - y1)\n",
    "        # print(\"Top alignment:\", )\n",
    "        y1 = max(0, y2 - 81)\n",
    "    if x2 - x1 < 20:\n",
    "        if cx - x1 < 10:\n",
    "            # print(\"Left alignment:\", 10 - (cx - x1))\n",
    "            x1 = max(0, cx - 10)\n",
    "        if x2 - cx < 11:\n",
    "            # print(\"Right alignment:\", 11 - (x2 - cx))\n",
    "            x2 = min(9600, cx + 11)\n",
    "    return y1, x1, y2, x2, vertical_diff\n",
    "\n",
    "def prepareData(path):\n",
    "    data = pd.read_csv(path)\n",
    "    data.drop(0, inplace=True)\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    data[\"plate\"] = np.nan\n",
    "    data[\"path\"] = np.nan\n",
    "    data[\"dx\"] = np.zeros(data.shape[0])\n",
    "    data[\"dy\"] = np.zeros(data.shape[0])\n",
    "    data[['_RAJ2000', '_DEJ2000']] = data[['_RAJ2000', '_DEJ2000']].astype(float)\n",
    "\n",
    "    # print(data.head())\n",
    "    return data\n",
    "\n",
    "def prepareFits(headers_path, fits_path, headers_pattern, fits_pattern):\n",
    "    headers_folder = listdir(headers_path)\n",
    "    fits_folder = listdir(fits_path)\n",
    "\n",
    "    fits_headers = []\n",
    "    fits_files = []\n",
    "\n",
    "    headers_pattern = headers_pattern\n",
    "    fits_pattern = fits_pattern\n",
    "\n",
    "    for entry in headers_folder:\n",
    "        if fnmatch(entry, headers_pattern):\n",
    "                fits_headers.append('./data/fits_headers/' + entry)\n",
    "\n",
    "    for entry in fits_folder:\n",
    "        if fnmatch(entry, fits_pattern):\n",
    "                fits_files.append('./data/fits_files/' + entry)\n",
    "\n",
    "    # print(fits_headers[:5])\n",
    "    # print('Files in headers folder:', len(headers_folder))\n",
    "    # print('Headers in headers folder:', len(fits_headers))\n",
    "    # print()\n",
    "    # print(fits_files[:5])\n",
    "    # print('Files in fits folder:', len(fits_folder))\n",
    "    # print('Fits files in fits folder:', len(fits_files))\n",
    "\n",
    "    fits_headers = np.array(fits_headers)\n",
    "    fits_files = np.array(fits_files)\n",
    "    fits_set = set(map(lambda x: x.split('/')[-1].split('.')[0], fits_files))\n",
    "\n",
    "    return fits_headers, fits_files, fits_set\n",
    "\n",
    "def getCoordinates(fits_headers, data):\n",
    "    coordinates = np.ones((len(fits_headers), data.shape[0], 2)) * (-1)\n",
    "\n",
    "    for i in range(len(fits_headers)):\n",
    "        hdulist = fits.open(fits_headers[i])\n",
    "        w = wcs.WCS(hdulist[0].header)\n",
    "\n",
    "        xy = w.all_world2pix(data[['_RAJ2000', '_DEJ2000']], 1, quiet=True)\n",
    "\n",
    "        matching_indices = np.where((xy[:,0] >= 0) & (xy[:,0] <= 9601) & (xy[:,1] >= 0) & (xy[:,1] <= 9601))[0]\n",
    "\n",
    "        coordinates[i][matching_indices] = xy[matching_indices]\n",
    "\n",
    "    return coordinates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = prepareData(\n",
    "    path='data/DFBS.csv')\n",
    "\n",
    "fits_headers, fits_files, fits_set = prepareFits(\n",
    "    headers_path='data/fits_headers',\n",
    "    fits_path='data/fits_files',\n",
    "    headers_pattern=\"*.hdr\",\n",
    "    fits_pattern=\"*.fits\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# coordinates = getCoordinates(\n",
    "#     fits_headers=fits_headers,\n",
    "#     data=data)\n",
    "# np.save('data/coordinates.csv', coordinates+1)\n",
    "coordinates = np.load('data/coordinates.csv.npy') - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "incorrect_coordinate_count = 0\n",
    "\n",
    "datapoint_plates = dict({})\n",
    "all_datapoints = set({})\n",
    "\n",
    "for i in range(len(fits_headers)):\n",
    "    plate = fits_headers[i].split('/')[-1].split('.')[0]\n",
    "    if plate in fits_set:\n",
    "        fbs_plate = fits.open('./data/fits_files/' + plate + '.fits')\n",
    "\n",
    "        plate_img = fbs_plate[0].data\n",
    "        del fbs_plate\n",
    "        \n",
    "        scaled_img = ((plate_img/plate_img.max())*255).astype(np.uint8)\n",
    "        del plate_img\n",
    "\n",
    "        if np.mean(scaled_img) < 127.5:\n",
    "            scaled_img = np.invert(scaled_img)\n",
    "\n",
    "        gblur = cv.GaussianBlur(scaled_img, (3, 3), 2, 2)\n",
    "        # mblur = cv.medianBlur(scaled_img, 3)\n",
    "\n",
    "        # del scaled_img #########################################################################\n",
    "\n",
    "        g_th = cv.adaptiveThreshold(gblur, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "                    cv.THRESH_BINARY_INV,21,2)\n",
    "        # m_th = cv.adaptiveThreshold(mblur, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "        #             cv.THRESH_BINARY_INV,11,2)\n",
    "\n",
    "        g_th_m = cv.adaptiveThreshold(gblur, 255, cv.ADAPTIVE_THRESH_MEAN_C,\\\n",
    "                    cv.THRESH_BINARY_INV,21,2)\n",
    "        # m_th_m = cv.adaptiveThreshold(mblur, 255, cv.ADAPTIVE_THRESH_MEAN_C,\\\n",
    "        #             cv.THRESH_BINARY_INV,11,2)\n",
    "\n",
    "        \n",
    "        del gblur #########################################################################\n",
    "        # del mblur #########################################################################\n",
    "\n",
    "        plate_datapoints = np.where(coordinates[i,:,0] >= 0)[0]\n",
    "        for pd_i in plate_datapoints:\n",
    "            if pd_i not in all_datapoints: ###############################################################################\n",
    "                all_datapoints.add(pd_i)\n",
    "            if pd_i not in datapoint_plates:\n",
    "                dx, dy = np.round(coordinates[i, pd_i]).astype(int)\n",
    "                if g_th[dy,dx] == 255:\n",
    "                    while insideCoordinate(g_th, dx, dy):\n",
    "                        dy += 1\n",
    "\n",
    "                    try:\n",
    "                        pavl_res = pavlidis(g_th, dy, dx)\n",
    "                        y1, x1, y2, x2, vd = getEdgeCoordinates(pavl_res, dx, dy)\n",
    "                        if y2 - y1 - vd > 20:\n",
    "                            # print(pd_i)\n",
    "                            # fig = plt.figure()\n",
    "                            # plt.gray()\n",
    "                            # ax1 = fig.add_subplot(221)\n",
    "                            # ax2 = fig.add_subplot(222)\n",
    "                            # ax3 = fig.add_subplot(223)\n",
    "                            # ax4 = fig.add_subplot(224)\n",
    "                            # ax1.imshow(scaled_img[y1:y2,x1:x2])\n",
    "                            # ax2.imshow(scaled_img[dy-100:dy+16,dx-15:dx+16])\n",
    "                            # ax3.imshow(g_th[y1:y2,x1:x2])\n",
    "                            # ax4.imshow(g_th_m[y1:y2,x1:x2])\n",
    "                            # plt.show()\n",
    "                            \n",
    "                            result = scaled_img[y1:y2,x1:x2]\n",
    "                            \n",
    "                            datapoint_plates[pd_i] = dict({\n",
    "                                'plate': plate,\n",
    "                                'dx': dx,\n",
    "                                'dy': dy,\n",
    "                            })\n",
    "                            \n",
    "                            image_path = f'data/images/{pd_i}__{data.loc[pd_i, \"Name\"]}.tiff'\n",
    "\n",
    "                            data.loc[pd_i, 'dx'] = dx\n",
    "                            data.loc[pd_i, 'dy'] = dy\n",
    "                            data.loc[pd_i, 'plate'] = plate\n",
    "                            data.loc[pd_i, 'path'] = image_path\n",
    "\n",
    "                            cv.imwrite(image_path, result)\n",
    "\n",
    "                            # img = cv.imread(image_path, cv.IMREAD_GRAYSCALE)\n",
    "                            # fig = plt.figure()\n",
    "                            # plt.gray()\n",
    "                            # ax1 = fig.add_subplot(121)\n",
    "                            # ax2 = fig.add_subplot(122)\n",
    "                            # ax1.imshow(result)\n",
    "                            # ax2.imshow(img)\n",
    "                            # plt.show()\n",
    "                    except AssertionError as err:\n",
    "                        print(err)\n",
    "                    except Exception as err2:\n",
    "                        print(err2)\n",
    "                        \n",
    "                else:\n",
    "                    # fig = plt.figure()\n",
    "                    # plt.gray()\n",
    "                    # ax1 = fig.add_subplot(131)\n",
    "                    # ax2 = fig.add_subplot(132)\n",
    "                    # ax3 = fig.add_subplot(133)\n",
    "                    # p = np.copy(g_th[dy-30:dy+10,dx-7:dx+8])\n",
    "                    # if g_th[dy,dx-1] == 0:\n",
    "                    #     g_th[dy,dx-1] = 50\n",
    "                    # else:\n",
    "                    #     g_th[dy,dx-1] = 200\n",
    "                    # if g_th[dy,dx+1] == 0:\n",
    "                    #     g_th[dy,dx+1] = 50\n",
    "                    # else:\n",
    "                    #     g_th[dy,dx+1] = 200\n",
    "                    # if g_th[dy-1,dx] == 0:\n",
    "                    #     g_th[dy-1,dx] = 50\n",
    "                    # else:\n",
    "                    #     g_th[dy-1,dx] = 200\n",
    "                    # if g_th[dy+1,dx] == 0:\n",
    "                    #     g_th[dy+1,dx] = 50\n",
    "                    # else:\n",
    "                    #     g_th[dy+1,dx] = 200\n",
    "                    print(pd_i)\n",
    "                    # ax1.imshow(g_th[dy-30:dy+10,dx-7:dx+8])\n",
    "                    # ax2.imshow(p)\n",
    "                    # ax3.imshow(scaled_img[dy-50:dy+10,dx-7:dx+8])\n",
    "                    # plt.show()\n",
    "                    incorrect_coordinate_count += 1\n",
    "            else:\n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = data[data['plate'].notna()]\n",
    "data.to_csv('data/DFBS_extracted.csv')\n",
    "print(len(all_datapoints))\n",
    "print(incorrect_coordinate_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/DFBS.csv')\n",
    "data.drop(0, inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data[\"plate\"] = np.nan\n",
    "data[\"dx\"] = np.zeros(data.shape[0])\n",
    "data[\"dy\"] = np.zeros(data.shape[0])\n",
    "data[['_RAJ2000', '_DEJ2000']] = data[['_RAJ2000', '_DEJ2000']].astype(float)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data.loc[0, 'dx'] = 1\n",
    "data.loc[0, 'dy'] = 1\n",
    "data.loc[0, 'plate'] = 'fbs0005_cor'\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "headers_folder = listdir('data/fits_headers')\n",
    "fits_folder = listdir('data/fits_files')\n",
    "\n",
    "fits_headers = []\n",
    "fits_files = []\n",
    "\n",
    "headers_pattern = \"*.hdr\"\n",
    "fits_pattern = \"*.fits\"\n",
    "\n",
    "for entry in headers_folder:\n",
    "    if fnmatch(entry, headers_pattern):\n",
    "            fits_headers.append('./data/fits_headers/' + entry)\n",
    "\n",
    "for entry in fits_folder:\n",
    "    if fnmatch(entry, fits_pattern):\n",
    "            fits_files.append('./data/fits_files/' + entry)\n",
    "\n",
    "print(fits_headers[:5])\n",
    "print('Files in headers folder:', len(headers_folder))\n",
    "print('Headers in headers folder:', len(fits_headers))\n",
    "print()\n",
    "print(fits_files[:5])\n",
    "print('Files in fits folder:', len(fits_folder))\n",
    "print('Fits files in fits folder:', len(fits_files))\n",
    "\n",
    "fits_headers = np.array(fits_headers)\n",
    "fits_files = np.array(fits_files)\n",
    "fits_set = set(map(lambda x: x.split('/')[-1].split('.')[0], fits_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Finding headers for each datapoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "coordinates = np.ones((len(fits_headers), data.shape[0], 2)) * (-1)\n",
    "\n",
    "for i in range(len(fits_headers)):\n",
    "    hdulist = fits.open(fits_headers[i])\n",
    "    w = wcs.WCS(hdulist[0].header)\n",
    "\n",
    "    xy = w.all_world2pix(data[['_RAJ2000', '_DEJ2000']], 1, quiet=True)\n",
    "\n",
    "    matching_indices = np.where((xy[:,0] >= 0) & (xy[:,0] <= 9601) & (xy[:,1] >= 0) & (xy[:,1] <= 9601))[0]\n",
    "    \n",
    "    coordinates[i][matching_indices] = xy[matching_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.array([1,2,3,4,5,6,7,8,9,10])[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.insert(1, 'TPA/pavlidis/build/lib.win-amd64-3.9')\n",
    "from pavlidis import pavlidis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def insideCoordinate(img, x, y):\n",
    "    if img[y,x-1] == 255 and img[y,x+1] == 255 and img[y-1,x] == 255 and img[y+1,x] == 255:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "t = False\n",
    "count_g_s = 0\n",
    "count_g_s_25 = 0\n",
    "count_m_s = 0\n",
    "count_m_s_25 = 0\n",
    "count_g_e = 0\n",
    "count_m_e = 0\n",
    "count_e = 0\n",
    "\n",
    "datapoint_plates = dict({})\n",
    "\n",
    "for i in range(len(fits_headers)):\n",
    "    plate = fits_headers[i].split('/')[-1].split('.')[0]\n",
    "    if plate in fits_set:\n",
    "        t0 = perf_counter()  \n",
    "        fbs_plate = fits.open('./data/fits_files/' + plate + '.fits')\n",
    "        # print(fbs_plate.info())\n",
    "\n",
    "        plate_img = fbs_plate[0].data\n",
    "        del fbs_plate #########################################################################\n",
    "\n",
    "        scaled_img = ((plate_img/plate_img.max())*255).astype(np.uint8)\n",
    "        del plate_img #########################################################################\n",
    "        if np.mean(scaled_img) < 127.5:\n",
    "            scaled_img = np.invert(scaled_img)\n",
    "\n",
    "        gblur = cv.GaussianBlur(scaled_img, (3, 3), 2, 2)\n",
    "        mblur = cv.medianBlur(scaled_img, 3)\n",
    "        \n",
    "        # del scaled_img #########################################################################\n",
    "\n",
    "        # g_th = cv.adaptiveThreshold(gblur, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "        #             cv.THRESH_BINARY,11,2)\n",
    "\n",
    "        # m_th = cv.adaptiveThreshold(mblur, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "        #             cv.THRESH_BINARY,11,2)\n",
    "\n",
    "        g_th_m = cv.adaptiveThreshold(gblur, 255, cv.ADAPTIVE_THRESH_MEAN_C,\\\n",
    "                    cv.THRESH_BINARY,11,2)\n",
    "        g_th_m_custom = cv.adaptiveThreshold(gblur, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "                    cv.THRESH_BINARY_INV,15,2)\n",
    "        m_th_m = cv.adaptiveThreshold(mblur, 255, cv.ADAPTIVE_THRESH_MEAN_C,\\\n",
    "                    cv.THRESH_BINARY,11,2)\n",
    "        \n",
    "        del gblur #########################################################################\n",
    "        del mblur #########################################################################\n",
    "\n",
    "        # ret3, th3 = cv.threshold(gblur,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "        # ret4, th4 = cv.threshold(mblur,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "\n",
    "        plate_datapoints = np.where(coordinates[i,:,0] >= 0)[0]\n",
    "        print('FBS Plate:', plate + '\\nDatapoint indices:', plate_datapoints)\n",
    "        for pd_i in plate_datapoints:\n",
    "            if pd_i not in datapoint_plates:\n",
    "                dx, dy = coordinates[i, pd_i].astype(int)\n",
    "                while insideCoordinate(g_th_m, dx, dy):\n",
    "                    dy += 1\n",
    "                \n",
    "                try:\n",
    "                    pavl_res = pavlidis(g_th_m, dx, dy)\n",
    "                    datapoint_plates[pd_i] = dict({\n",
    "                        'plate': plate,\n",
    "                        'dx': dx,\n",
    "                        'dy': dy,\n",
    "                    #     'location': pavl_res\n",
    "                    })\n",
    "                    # t = True\n",
    "                    # break\n",
    "                    if pavl_res[:,0].max() - pavl_res[:,0].min() > 25:\n",
    "                        print('Stacvec G', pd_i, dx, dy)\n",
    "                        count_g_s += 1\n",
    "                        # fig = plt.figure()\n",
    "                        # plt.gray()\n",
    "                        # ax1 = fig.add_subplot(121)  # top left side\n",
    "                        # ax2 = fig.add_subplot(122)  # top right side\n",
    "                        # ax1.imshow(scaled_img[pavl_res[:,0].min():pavl_res[:,0].max()+2, pavl_res[:,1].min():pavl_res[:,1].max()+2])\n",
    "                        # ax2.imshow(g_th_m[pavl_res[:,0].min():pavl_res[:,0].max()+2, pavl_res[:,1].min():pavl_res[:,1].max()+2])\n",
    "                        # plt.show()\n",
    "                    else:\n",
    "                        count_g_s_25 += 1\n",
    "                except AssertionError:\n",
    "                    count_g_e += 1\n",
    "                    # print('Gaussian ERROR:', pd_i, dx, dy)\n",
    "                    try:\n",
    "                        pavl_res = pavlidis(m_th_m, dx, dy)\n",
    "                        datapoint_plates[pd_i] = dict({\n",
    "                            'plate': plate,\n",
    "                            'dx': dx,\n",
    "                            'dy': dy,\n",
    "                            # 'location': pavl_res\n",
    "                        })\n",
    "                        # t = True\n",
    "                        # break\n",
    "                        if pavl_res[:,0].max() - pavl_res[:,0].min() > 25:\n",
    "                            print('Stacvec M', pd_i, dx, dy)\n",
    "                            count_m_s += 1\n",
    "                            # fig = plt.figure()\n",
    "                            # plt.gray()\n",
    "                            # ax1 = fig.add_subplot(121)  # top left side\n",
    "                            # ax2 = fig.add_subplot(122)  # top right side\n",
    "                            # ax1.imshow(scaled_img[pavl_res[:,0].min():pavl_res[:,0].max()+2, pavl_res[:,1].min():pavl_res[:,1].max()+2])\n",
    "                            # ax2.imshow(m_th_m[pavl_res[:,0].min():pavl_res[:,0].max()+2, pavl_res[:,1].min():pavl_res[:,1].max()+2])\n",
    "                            # plt.show()\n",
    "                        else:\n",
    "                            count_m_s_25 += 1\n",
    "                    except AssertionError:\n",
    "                        count_m_e += 1\n",
    "                        pass\n",
    "                        # print('Median ERROR:', pd_i, dx, dy)\n",
    "                except:\n",
    "                    count_e += 1\n",
    "                    print(\"Eshchyo smth happened\")\n",
    "        # t = True\n",
    "        # break\n",
    "        print(perf_counter() - t0)\n",
    "    if t:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data.iloc[1451]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def getHeader(row):\n",
    "    global count\n",
    "    index, value = row\n",
    "    indices = np.where(coordinates[:, index] >= 0)[0]\n",
    "    # for i in indices:\n",
    "        # print(fits_headers[i], end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# list(map(getHeader, data.iterrows()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fits_headers[0].split('/')[-1].split('_')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "a = set({1,2,3,6,'derfed','adfrd'})\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "abe97b4297a04eb9b59942013a51b5b6b6dd824dcfaba919a0d03fdddda38a68"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
