{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f429a84b",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "004dac34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import pandas as pd\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy import wcs\n",
    "\n",
    "from pavlidis import pavlidis\n",
    "from _helpers import make_directory, prepareData, can_go_down\n",
    "\n",
    "from fnmatch import fnmatch\n",
    "from os import listdir, path as os_path\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "# from time import perf_counter\n",
    "\n",
    "import warnings\n",
    "from astropy.utils.exceptions import AstropyUserWarning\n",
    "from astropy.wcs import FITSFixedWarning\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=AstropyUserWarning)\n",
    "warnings.filterwarnings(action='ignore', category=FITSFixedWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65aa4716",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b0c92ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## blockSize: Size of a pixel neighborhood that is used to calculate a threshold value for the pixel: 3, 5, 7,\n",
    "# and so on.\n",
    "## C: Constant subtracted from the mean or weighted mean (see the details below). Normally, it is positive but may\n",
    "# be zero or negative as well.\n",
    "## calculate_coordinates: Whether to calculate the coordinates of dataset objects using headers or not.\n",
    "\n",
    "block_size = 19\n",
    "constant = 2\n",
    "calculate_coordinates = True\n",
    "\n",
    "mode = 'train'  # choices=('train', 'test')\n",
    "csv_name = 'Subtypes'  # choices=('Subtypes', 'Combined')\n",
    "class_column = 'Sp type'  # choices=('Sp type', 'Cl')\n",
    "\n",
    "data_root = '/home/stepan/Data/DFBS'; assert data_root != None\n",
    "\n",
    "if mode == 'train':\n",
    "    output_path = f'{data_root}/Plates/{csv_name}/{block_size}_{constant}'\n",
    "else:\n",
    "    output_path = f'{data_root}/Inference/{csv_name}/{block_size}_{constant}'\n",
    "\n",
    "fits_path = os_path.join(data_root, 'fits_files')\n",
    "headers_path = os_path.join(data_root, 'fits_headers')\n",
    "\n",
    "raw_folder = 'images'\n",
    "classified_folder = 'images_classified'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48783d87",
   "metadata": {},
   "source": [
    "## Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c80cfa",
   "metadata": {},
   "source": [
    "### Data acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fafedf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prepareData(\n",
    "    path=f'{data_root}/Datasets/{csv_name}.csv')\n",
    "print(data.head(), '\\n')\n",
    "\n",
    "fits_headers, fits_set = prepareFits(\n",
    "    headers_path=headers_path,\n",
    "    fits_path=fits_path,\n",
    "    headers_pattern=\"*.fits.hdr\",\n",
    "    fits_pattern=\"*.fits\")\n",
    "\n",
    "if calculate_coordinates:\n",
    "    coordinates, plates_containing_objects = getCoordinates(\n",
    "        fits_headers=fits_headers,\n",
    "        ra_dec=data[['_RAJ2000', '_DEJ2000']])\n",
    "    np.save(f'{data_root}/Coordinates/{csv_name}', coordinates + 1)\n",
    "else:\n",
    "    print('Loading coordinates ...')\n",
    "    coordinates = np.load(f'{data_root}/Coordinates/{csv_name}.npy') - 1\n",
    "    plates_containing_objects = fits_set\n",
    "\n",
    "print('Done.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd79a1b",
   "metadata": {},
   "source": [
    "### Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d651383b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoint_plates = dict({})\n",
    "all_datapoints = set({})  # For statistics\n",
    "\n",
    "incorrect_datapoints = dict({})\n",
    "short_images_extracted_count = 0\n",
    "short_20_images = set({})\n",
    "\n",
    "n_headers = len(fits_headers)\n",
    "\n",
    "print('Extracting objects by plate ...')\n",
    "\n",
    "plates_dataset = pd.DataFrame(columns=data.columns)\n",
    "plate_dir = output_path\n",
    "\n",
    "if mode == 'test':\n",
    "    make_directory(f'{plate_dir}/{raw_folder}')\n",
    "\n",
    "for i in tqdm(range(n_headers)):\n",
    "    plate = fits_headers[i].split('/')[-1].split('.')[0]\n",
    "    plate_num = plate.split('_')[0][3:]\n",
    "\n",
    "    if plate in fits_set and plate in plates_containing_objects:\n",
    "        ###################\n",
    "        # t0 = perf_counter()\n",
    "        ###################\n",
    "        if mode == 'train':\n",
    "            plate_dir = os_path.join(output_path, plate)\n",
    "\n",
    "        if mode == 'train':\n",
    "            make_directory(f'{plate_dir}/{raw_folder}')\n",
    "            for class_name in np.unique(data[class_column]):\n",
    "                make_directory(f'{plate_dir}/{classified_folder}/{class_name}')\n",
    "\n",
    "        ###################\n",
    "        # t1 = perf_counter()\n",
    "        # print(f'Directory preparations: {t1 - t0}')\n",
    "        ###################\n",
    "\n",
    "        fbs_plate = fits.open(f'{fits_path}/{plate}.fits')\n",
    "\n",
    "        ###################\n",
    "        # t2 = perf_counter()\n",
    "        # print(f'Opening fits: {t2 - t1}')\n",
    "        ###################\n",
    "\n",
    "        plate_img = np.array(fbs_plate[0].data, dtype=np.uint16)\n",
    "        shape_y, shape_x = plate_img.shape\n",
    "        del fbs_plate\n",
    "\n",
    "        scaled_img = ((plate_img - plate_img.min()) / (plate_img.max() - plate_img.min()) * 255).astype(np.uint8)\n",
    "\n",
    "        if np.mean(scaled_img) < 127.5:\n",
    "            scaled_img = np.invert(scaled_img)\n",
    "\n",
    "        ###################\n",
    "        # t3 = perf_counter()\n",
    "        # print(f'Scaling: {t3 - t2}')\n",
    "        ###################\n",
    "\n",
    "        gblur = cv.GaussianBlur(scaled_img, (3, 3), 2, 2)\n",
    "        del scaled_img\n",
    "\n",
    "        ###################\n",
    "        # t4 = perf_counter()\n",
    "        # print(f'Gaussian blurring: {t4 - t3}')\n",
    "        ###################\n",
    "\n",
    "        g_th = cv.adaptiveThreshold(gblur, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                    cv.THRESH_BINARY_INV, blockSize=block_size, C=constant)\n",
    "        del gblur\n",
    "\n",
    "        ###################\n",
    "        # t5 = perf_counter()\n",
    "        # print(f'Thresholding: {t5 - t4}')\n",
    "        ###################\n",
    "\n",
    "        plate_datapoints = getPlateCoordinates(coordinates[i], shape_x, shape_y)\n",
    "\n",
    "        ###################\n",
    "        # t6 = perf_counter()\n",
    "        # print(f'Getting plate coordinates: {t6 - t5}')\n",
    "        ###################\n",
    "\n",
    "        for pd_i in plate_datapoints:\n",
    "\n",
    "            if pd_i not in all_datapoints:  # For statistics\n",
    "                all_datapoints.add(pd_i)\n",
    "\n",
    "            dx, dy = np.round(coordinates[i, pd_i]).astype(int)\n",
    "            if g_th[dy, dx] == 255:\n",
    "                while (dy < shape_y - 1) and can_go_down(g_th, dx, dy):\n",
    "                    dy += 1\n",
    "\n",
    "                y1, x1, y2, x2 = getContourEdges(g_th, dx, dy)\n",
    "                if all([y1, x1, y2, x2]):\n",
    "                    result = plate_img[y1:y2, x1:x2]\n",
    "                    # result_sized = cv.resize(result, (20, 140))\n",
    "\n",
    "                    datapoint_plates[pd_i] = dict({  ##########################\n",
    "                        'plate': plate,\n",
    "                        'dx': dx,\n",
    "                        'dy': dy,\n",
    "                    })\n",
    "\n",
    "                    full_index = f'{plate_num}_{pd_i}'\n",
    "\n",
    "                    if mode == 'train':\n",
    "                        image_path = f'{plate_dir}/{raw_folder}/{pd_i}__{data.iloc[pd_i][\"Name\"]}.tiff'\n",
    "\n",
    "                        classes_path = f'{plate_dir}/{classified_folder}/{data.iloc[pd_i][class_column]}' \\\n",
    "                                       f'/{pd_i}__{data.iloc[pd_i][\"Name\"]}.tiff'\n",
    "\n",
    "                        cv.imwrite(classes_path, result)\n",
    "\n",
    "                    else:\n",
    "                        image_path = f'{plate_dir}/{raw_folder}/{full_index}__{data.iloc[pd_i][\"Name\"]}.tiff'\n",
    "\n",
    "                    plates_dataset.loc[full_index] = data.iloc[pd_i]\n",
    "                    plates_dataset.loc[full_index, 'dx'] = dx\n",
    "                    plates_dataset.loc[full_index, 'dy'] = dy\n",
    "                    plates_dataset.loc[full_index, 'plate'] = plate\n",
    "                    plates_dataset.loc[full_index, 'path'] = image_path\n",
    "\n",
    "                    cv.imwrite(image_path, result)\n",
    "\n",
    "                    incorrect_datapoints.pop(pd_i, None)\n",
    "                else:\n",
    "                    if pd_i not in short_20_images:\n",
    "                        short_20_images.add(pd_i)\n",
    "\n",
    "            else:\n",
    "                extracted = False\n",
    "                for i_x in range(max(0, dx - 2), min(shape_x, dx + 3)):\n",
    "                    if extracted:\n",
    "                        break\n",
    "                    for i_y in range(dy, max(-1, dy - 3), -1):\n",
    "                        if extracted:\n",
    "                            break\n",
    "                        if i_x == dx and i_y == dy:\n",
    "                            continue\n",
    "                        if g_th[i_y, i_x] == 255:\n",
    "                            # Copy i_y\n",
    "                            y = int(i_y)\n",
    "\n",
    "                            while (y < shape_y - 1) and can_go_down(g_th, i_x, y):\n",
    "                                y += 1\n",
    "\n",
    "                            # try:\n",
    "                            y1, x1, y2, x2 = getContourEdges(g_th, i_x, y)\n",
    "                            if all([y1, x1, y2, x2]):\n",
    "                                result = plate_img[y1:y2, x1:x2]\n",
    "\n",
    "                                datapoint_plates[pd_i] = dict({  ##########################\n",
    "                                    'plate': plate,\n",
    "                                    'dx': i_x,\n",
    "                                    'dy': y,\n",
    "                                })\n",
    "\n",
    "                                full_index = f'{plate_num}_{pd_i}'\n",
    "\n",
    "                                if mode == 'train':\n",
    "                                    image_path = f'{plate_dir}/{raw_folder}/{pd_i}__{data.iloc[pd_i][\"Name\"]}.tiff'\n",
    "\n",
    "                                    classes_path = f'{plate_dir}/{classified_folder}/' \\\n",
    "                                        f'{data.iloc[pd_i][class_column]}/{pd_i}__{data.iloc[pd_i][\"Name\"]}.tiff'\n",
    "\n",
    "                                    cv.imwrite(classes_path, result)\n",
    "                                else:\n",
    "                                    image_path = f'{plate_dir}/{raw_folder}/{full_index}__{data.iloc[pd_i][\"Name\"]}.tiff'\n",
    "\n",
    "                                plates_dataset.loc[full_index] = data.iloc[pd_i]\n",
    "                                plates_dataset.loc[full_index, 'dx'] = dx\n",
    "                                plates_dataset.loc[full_index, 'dy'] = dy\n",
    "                                plates_dataset.loc[full_index, 'plate'] = plate\n",
    "                                plates_dataset.loc[full_index, 'path'] = image_path\n",
    "\n",
    "                                cv.imwrite(image_path, result)\n",
    "\n",
    "                                incorrect_datapoints.pop(pd_i, None)\n",
    "\n",
    "                                extracted = True\n",
    "                                short_images_extracted_count += 1\n",
    "\n",
    "                if not extracted:\n",
    "                    if pd_i not in incorrect_datapoints:\n",
    "                        incorrect_datapoints[pd_i] = [plate]\n",
    "                    else:\n",
    "                        incorrect_datapoints[pd_i].append(plate)\n",
    "\n",
    "        ###################\n",
    "        # t7 = perf_counter()\n",
    "        # print(f'Extracting: {t7 - t6}')\n",
    "        ###################\n",
    "\n",
    "        ###################\n",
    "        # print(f'Saving csv: {perf_counter() - t7}')\n",
    "        ###################\n",
    "\n",
    "plates_dataset.to_csv(f'{plate_dir}/extracted.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8604c8",
   "metadata": {},
   "source": [
    "## Just for Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f04f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print('all_datapoints:', len(all_datapoints))\n",
    "print('incorrect_datapoints:', len(incorrect_datapoints))\n",
    "print('short_20_images:', len(short_20_images.difference(incorrect_datapoints, datapoint_plates)))\n",
    "print('extracted images count:',\n",
    "      len(all_datapoints)\n",
    "      - len(short_20_images.difference(incorrect_datapoints, datapoint_plates))\n",
    "      - len(incorrect_datapoints))\n",
    "print('short_images_extracted_count:', short_images_extracted_count)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
